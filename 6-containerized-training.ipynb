{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3802510a-b813-40c2-a77e-906e191df9d2",
   "metadata": {},
   "source": [
    "## Configure environment settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d80c27-6e4d-4d55-8e5c-fc8fa40020bf",
   "metadata": {},
   "source": [
    "Set location paths, connections strings, and other environment settings. Make sure to update   `REGION`, and `ARTIFACT_STORE`  with the settings reflecting your lab environment. \n",
    "\n",
    "- `REGION` - the compute region for Vertex AI Training and Prediction\n",
    "- `ARTIFACT_STORE` - A GCS bucket in the created in the same region."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9d55d2-f592-40aa-af7d-9926ae0fba1b",
   "metadata": {},
   "source": [
    "Containerized Training Cloud Serving\n",
    "- `Phase 1` - (Before ML Pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "28d72e95-efe9-450f-a629-1a53d51e4b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "497ee2f8-6173-467b-b80a-f63ea1ce0bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = \"us-east1\"\n",
    "\n",
    "PROJECT_ID = !(gcloud config get-value core/project)\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "\n",
    "ARTIFACT_STORE = f\"gs://{PROJECT_ID}-beer-artifact-store\"\n",
    "\n",
    "DATA_ROOT = f\"{ARTIFACT_STORE}/data\"\n",
    "JOB_DIR_ROOT = f\"{ARTIFACT_STORE}/jobs\"\n",
    "TRAINING_FILE_PATH = f\"{DATA_ROOT}/train.parquet\"\n",
    "VALIDATION_FILE_PATH = f\"{DATA_ROOT}/valid.parquet\"\n",
    "API_ENDPOINT = f\"{REGION}-aiplatform.googleapis.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9c4049d0-e395-4c17-8b28-011316630e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"JOB_DIR_ROOT\"] = JOB_DIR_ROOT\n",
    "os.environ[\"TRAINING_FILE_PATH\"] = TRAINING_FILE_PATH\n",
    "os.environ[\"VALIDATION_FILE_PATH\"] = VALIDATION_FILE_PATH\n",
    "os.environ[\"PROJECT_ID\"] = PROJECT_ID\n",
    "os.environ[\"REGION\"] = REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9cbe53f6-febd-492d-8d85-a65ee900c877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://qwiklabs-asl-04-5e165f533cac-beer-artifact-store/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls | grep ^{ARTIFACT_STORE}/$ || gsutil mb -l {REGION} {ARTIFACT_STORE}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a54a91-79ad-4e10-a3cf-fd3aa1d789cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Package the script into a docker image.\n",
    "\n",
    "Notice that we are installing specific versions of `scikit-learn` and `pandas` in the training image. This is done to make sure that the training runtime in the training container is aligned with the serving runtime in the serving container. \n",
    "\n",
    "Make sure to update the URI for the base image so that it points to your project's **Container Registry**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9a7be472-cff7-452e-9337-1c169823ef5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_APP_FOLDER = \"training_app\"\n",
    "os.makedirs(TRAINING_APP_FOLDER, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6caa7193-c966-4aa2-a2ee-9833857b852b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting training_app/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile {TRAINING_APP_FOLDER}/Dockerfile\n",
    "\n",
    "FROM gcr.io/deeplearning-platform-release/base-cpu\n",
    "RUN pip install -U fire cloudml-hypertune implicit\n",
    "WORKDIR /app\n",
    "COPY train.py .\n",
    "\n",
    "ENTRYPOINT [\"python\", \"train.py\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "70e86dde-f309-4735-84c8-12ff69d08658",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_NAME = \"trainer_image\"\n",
    "IMAGE_TAG = \"latest\"\n",
    "IMAGE_URI = f\"gcr.io/{PROJECT_ID}/{IMAGE_NAME}:{IMAGE_TAG}\"\n",
    "\n",
    "os.environ[\"IMAGE_URI\"] = IMAGE_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cfd37de2-dab7-45a3-b944-da4c4c7c085f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 4 file(s) totalling 16.3 KiB before compression.\n",
      "Uploading tarball of [training_app] to [gs://qwiklabs-asl-04-5e165f533cac_cloudbuild/source/1654655329.564066-ee0e5fe600cf442e8f7cf95d9c5ab6e5.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/qwiklabs-asl-04-5e165f533cac/locations/global/builds/3129b0a1-d610-4d25-90ee-f4c00ad774d2].\n",
      "Logs are available at [https://console.cloud.google.com/cloud-build/builds/3129b0a1-d610-4d25-90ee-f4c00ad774d2?project=547029906128].\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"3129b0a1-d610-4d25-90ee-f4c00ad774d2\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://qwiklabs-asl-04-5e165f533cac_cloudbuild/source/1654655329.564066-ee0e5fe600cf442e8f7cf95d9c5ab6e5.tgz#1654655329829270\n",
      "Copying gs://qwiklabs-asl-04-5e165f533cac_cloudbuild/source/1654655329.564066-ee0e5fe600cf442e8f7cf95d9c5ab6e5.tgz#1654655329829270...\n",
      "/ [1 files][  3.2 KiB/  3.2 KiB]                                                \n",
      "Operation completed over 1 objects/3.2 KiB.\n",
      "BUILD\n",
      "Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Sending build context to Docker daemon  22.02kB\n",
      "Step 1/5 : FROM gcr.io/deeplearning-platform-release/base-cpu\n",
      "latest: Pulling from deeplearning-platform-release/base-cpu\n",
      "d5fd17ec1767: Pulling fs layer\n",
      "adb65a4cea80: Pulling fs layer\n",
      "4f4fb700ef54: Pulling fs layer\n",
      "4ae9dce86192: Pulling fs layer\n",
      "3c97dd6fc917: Pulling fs layer\n",
      "9a421421a9c6: Pulling fs layer\n",
      "8c3aa27ae5ff: Pulling fs layer\n",
      "ed3dcc4cfb6c: Pulling fs layer\n",
      "3debde04b610: Pulling fs layer\n",
      "f5164395e213: Pulling fs layer\n",
      "7c0e9eccc936: Pulling fs layer\n",
      "d78c60a0dcbe: Pulling fs layer\n",
      "ff2acd98ca45: Pulling fs layer\n",
      "a11a78983f17: Pulling fs layer\n",
      "6b33fb6f0d3a: Pulling fs layer\n",
      "3293f65cfcaa: Pulling fs layer\n",
      "aa9e1ad00162: Pulling fs layer\n",
      "9c25ce1cf557: Pulling fs layer\n",
      "8c3aa27ae5ff: Waiting\n",
      "ed3dcc4cfb6c: Waiting\n",
      "3debde04b610: Waiting\n",
      "f5164395e213: Waiting\n",
      "7c0e9eccc936: Waiting\n",
      "d78c60a0dcbe: Waiting\n",
      "ff2acd98ca45: Waiting\n",
      "a11a78983f17: Waiting\n",
      "6b33fb6f0d3a: Waiting\n",
      "3293f65cfcaa: Waiting\n",
      "4ae9dce86192: Waiting\n",
      "3c97dd6fc917: Waiting\n",
      "9a421421a9c6: Waiting\n",
      "aa9e1ad00162: Waiting\n",
      "9c25ce1cf557: Waiting\n",
      "4f4fb700ef54: Download complete\n",
      "adb65a4cea80: Verifying Checksum\n",
      "adb65a4cea80: Download complete\n",
      "d5fd17ec1767: Verifying Checksum\n",
      "d5fd17ec1767: Download complete\n",
      "9a421421a9c6: Verifying Checksum\n",
      "9a421421a9c6: Download complete\n",
      "8c3aa27ae5ff: Verifying Checksum\n",
      "8c3aa27ae5ff: Download complete\n",
      "ed3dcc4cfb6c: Verifying Checksum\n",
      "ed3dcc4cfb6c: Download complete\n",
      "3c97dd6fc917: Verifying Checksum\n",
      "3c97dd6fc917: Download complete\n",
      "3debde04b610: Verifying Checksum\n",
      "3debde04b610: Download complete\n",
      "f5164395e213: Verifying Checksum\n",
      "f5164395e213: Download complete\n",
      "7c0e9eccc936: Verifying Checksum\n",
      "7c0e9eccc936: Download complete\n",
      "d78c60a0dcbe: Verifying Checksum\n",
      "d78c60a0dcbe: Download complete\n",
      "ff2acd98ca45: Verifying Checksum\n",
      "ff2acd98ca45: Download complete\n",
      "a11a78983f17: Verifying Checksum\n",
      "a11a78983f17: Download complete\n",
      "6b33fb6f0d3a: Verifying Checksum\n",
      "6b33fb6f0d3a: Download complete\n",
      "3293f65cfcaa: Verifying Checksum\n",
      "3293f65cfcaa: Download complete\n",
      "9c25ce1cf557: Verifying Checksum\n",
      "9c25ce1cf557: Download complete\n",
      "4ae9dce86192: Verifying Checksum\n",
      "4ae9dce86192: Download complete\n",
      "d5fd17ec1767: Pull complete\n",
      "adb65a4cea80: Pull complete\n",
      "4f4fb700ef54: Pull complete\n",
      "aa9e1ad00162: Verifying Checksum\n",
      "aa9e1ad00162: Download complete\n",
      "4ae9dce86192: Pull complete\n",
      "3c97dd6fc917: Pull complete\n",
      "9a421421a9c6: Pull complete\n",
      "8c3aa27ae5ff: Pull complete\n",
      "ed3dcc4cfb6c: Pull complete\n",
      "3debde04b610: Pull complete\n",
      "f5164395e213: Pull complete\n",
      "7c0e9eccc936: Pull complete\n",
      "d78c60a0dcbe: Pull complete\n",
      "ff2acd98ca45: Pull complete\n",
      "a11a78983f17: Pull complete\n",
      "6b33fb6f0d3a: Pull complete\n",
      "3293f65cfcaa: Pull complete\n",
      "aa9e1ad00162: Pull complete\n",
      "9c25ce1cf557: Pull complete\n",
      "Digest: sha256:8ad8673b3dcf0645737cc7adf32c0bacec683532ffdeae26fde760998c262972\n",
      "Status: Downloaded newer image for gcr.io/deeplearning-platform-release/base-cpu:latest\n",
      " ---> 4d10005d4e6f\n",
      "Step 2/5 : RUN pip install -U fire cloudml-hypertune implicit\n",
      " ---> Running in 94af22e89133\n",
      "Collecting fire\n",
      "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 87.7/87.7 kB 4.6 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting cloudml-hypertune\n",
      "  Downloading cloudml-hypertune-0.1.0.dev6.tar.gz (3.2 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting implicit\n",
      "  Downloading implicit-0.5.2-cp37-cp37m-manylinux2014_x86_64.whl (18.5 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.5/18.5 MB 34.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from fire) (1.16.0)\n",
      "Collecting termcolor\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from implicit) (1.19.5)\n",
      "Requirement already satisfied: scipy>=0.16 in /opt/conda/lib/python3.7/site-packages (from implicit) (1.7.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from implicit) (4.64.0)\n",
      "Building wheels for collected packages: fire, cloudml-hypertune, termcolor\n",
      "  Building wheel for fire (setup.py): started\n",
      "  Building wheel for fire (setup.py): finished with status 'done'\n",
      "  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115942 sha256=55bf253ecc0148f8a9accc1cdf7c7b609897e8118376d5f0dc19e11b48b84c63\n",
      "  Stored in directory: /root/.cache/pip/wheels/8a/67/fb/2e8a12fa16661b9d5af1f654bd199366799740a85c64981226\n",
      "  Building wheel for cloudml-hypertune (setup.py): started\n",
      "  Building wheel for cloudml-hypertune (setup.py): finished with status 'done'\n",
      "  Created wheel for cloudml-hypertune: filename=cloudml_hypertune-0.1.0.dev6-py2.py3-none-any.whl size=3987 sha256=59502fde3cfe3924c3dabeb2c216291e826045e0b8cc48183069ff91b9777835\n",
      "  Stored in directory: /root/.cache/pip/wheels/a7/ff/87/e7bed0c2741fe219b3d6da67c2431d7f7fedb183032e00f81e\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4848 sha256=91935e51c0647ffc3db18a77e81baf4c5a34cf6f72cf31a56d4e0f629e5004e8\n",
      "  Stored in directory: /root/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
      "Successfully built fire cloudml-hypertune termcolor\n",
      "Installing collected packages: termcolor, cloudml-hypertune, fire, implicit\n",
      "Successfully installed cloudml-hypertune-0.1.0.dev6 fire-0.4.0 implicit-0.5.2 termcolor-1.1.0\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRemoving intermediate container 94af22e89133\n",
      " ---> 2066d60e9272\n",
      "Step 3/5 : WORKDIR /app\n",
      " ---> Running in 47b0f774e62b\n",
      "Removing intermediate container 47b0f774e62b\n",
      " ---> 91a91d28f8af\n",
      "Step 4/5 : COPY train.py .\n",
      " ---> ca8b665528e7\n",
      "Step 5/5 : ENTRYPOINT [\"python\", \"train.py\"]\n",
      " ---> Running in 550b5211a6be\n",
      "Removing intermediate container 550b5211a6be\n",
      " ---> 93a204e01d08\n",
      "Successfully built 93a204e01d08\n",
      "Successfully tagged gcr.io/qwiklabs-asl-04-5e165f533cac/trainer_image:latest\n",
      "PUSH\n",
      "Pushing gcr.io/qwiklabs-asl-04-5e165f533cac/trainer_image:latest\n",
      "The push refers to repository [gcr.io/qwiklabs-asl-04-5e165f533cac/trainer_image]\n",
      "c4c41258525e: Preparing\n",
      "8e4fe2554462: Preparing\n",
      "90bbf6b97c38: Preparing\n",
      "a74d37ed3ebe: Preparing\n",
      "358d0c97e748: Preparing\n",
      "a72622d8d85c: Preparing\n",
      "a44ab01c5179: Preparing\n",
      "5dc3e696ff5b: Preparing\n",
      "614f43fff4a9: Preparing\n",
      "ae2d9c14a32d: Preparing\n",
      "7d7cd198ee7d: Preparing\n",
      "186b46a1d19e: Preparing\n",
      "ac6ab83c1c63: Preparing\n",
      "c8e5c31d7bf8: Preparing\n",
      "3e7b03bffb47: Preparing\n",
      "cebed4d6cdf8: Preparing\n",
      "5f70bf18a086: Preparing\n",
      "8320c4cf558f: Preparing\n",
      "67fe02a0cfc8: Preparing\n",
      "5f70bf18a086: Preparing\n",
      "65f26f75faab: Preparing\n",
      "bf8cedc62fb3: Preparing\n",
      "186b46a1d19e: Waiting\n",
      "ac6ab83c1c63: Waiting\n",
      "c8e5c31d7bf8: Waiting\n",
      "3e7b03bffb47: Waiting\n",
      "cebed4d6cdf8: Waiting\n",
      "5f70bf18a086: Waiting\n",
      "8320c4cf558f: Waiting\n",
      "67fe02a0cfc8: Waiting\n",
      "65f26f75faab: Waiting\n",
      "bf8cedc62fb3: Waiting\n",
      "a72622d8d85c: Waiting\n",
      "a44ab01c5179: Waiting\n",
      "5dc3e696ff5b: Waiting\n",
      "614f43fff4a9: Waiting\n",
      "ae2d9c14a32d: Waiting\n",
      "7d7cd198ee7d: Waiting\n",
      "358d0c97e748: Layer already exists\n",
      "a74d37ed3ebe: Layer already exists\n",
      "a72622d8d85c: Layer already exists\n",
      "a44ab01c5179: Layer already exists\n",
      "5dc3e696ff5b: Layer already exists\n",
      "614f43fff4a9: Layer already exists\n",
      "ae2d9c14a32d: Layer already exists\n",
      "7d7cd198ee7d: Layer already exists\n",
      "186b46a1d19e: Layer already exists\n",
      "ac6ab83c1c63: Layer already exists\n",
      "3e7b03bffb47: Layer already exists\n",
      "c8e5c31d7bf8: Layer already exists\n",
      "cebed4d6cdf8: Layer already exists\n",
      "5f70bf18a086: Layer already exists\n",
      "8320c4cf558f: Layer already exists\n",
      "67fe02a0cfc8: Layer already exists\n",
      "65f26f75faab: Layer already exists\n",
      "bf8cedc62fb3: Layer already exists\n",
      "c4c41258525e: Pushed\n",
      "8e4fe2554462: Pushed\n",
      "90bbf6b97c38: Pushed\n",
      "latest: digest: sha256:5a0c1b6a300dff80a75aa6591b4dd36987cb909169e72b5421e2d5c51dfd65c2 size: 4913\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                                      IMAGES                                                       STATUS\n",
      "3129b0a1-d610-4d25-90ee-f4c00ad774d2  2022-06-08T02:28:50+00:00  1M55S     gs://qwiklabs-asl-04-5e165f533cac_cloudbuild/source/1654655329.564066-ee0e5fe600cf442e8f7cf95d9c5ab6e5.tgz  gcr.io/qwiklabs-asl-04-5e165f533cac/trainer_image (+1 more)  SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!gcloud builds submit --tag $IMAGE_URI $TRAINING_APP_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df893958-0b4b-4427-bc40-afb59dce5e41",
   "metadata": {},
   "source": [
    "## Submit an Vertex AI hyperparameter tuning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6af82820-d836-4fce-baa8-a046adef2c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTAMP = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "JOB_NAME = f\"beer_recom_tuning_{TIMESTAMP}\"\n",
    "JOB_DIR = f\"{JOB_DIR_ROOT}/{JOB_NAME}\"\n",
    "\n",
    "os.environ[\"JOB_NAME\"] = JOB_NAME\n",
    "os.environ[\"JOB_DIR\"] = JOB_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "045e6257-aa09-442e-bfab-79fe39378180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOB_NAME: beer_recom_tuning_20220608_015533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-east1-aiplatform.googleapis.com/]\n",
      "Hyperparameter tuning job [8556929451957420032] submitted successfully.\n",
      "\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai hp-tuning-jobs describe 8556929451957420032 --region=us-east1\n",
      "\n",
      "Job State: JOB_STATE_PENDING\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "CONFIG_YAML=config.yaml\n",
    "\n",
    "gcloud ai hp-tuning-jobs create \\\n",
    "    --region=$REGION \\\n",
    "    --display-name=$JOB_NAME \\\n",
    "    --config=$CONFIG_YAML \\\n",
    "    --max-trial-count=5 \\\n",
    "    --parallel-trial-count=5\n",
    "\n",
    "echo \"JOB_NAME: $JOB_NAME\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "449b597e-a2ef-46a9-bfb5-f5b30d5d5fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<google.cloud.aiplatform.jobs.HyperparameterTuningJob object at 0x7f4271c967d0> \n",
      "resource name: projects/547029906128/locations/us-east1/hyperparameterTuningJobs/1783304506159661056, <google.cloud.aiplatform.jobs.HyperparameterTuningJob object at 0x7f4271cf3250> \n",
      "resource name: projects/547029906128/locations/us-east1/hyperparameterTuningJobs/1515551434563649536, <google.cloud.aiplatform.jobs.HyperparameterTuningJob object at 0x7f4271c86e50> \n",
      "resource name: projects/547029906128/locations/us-east1/hyperparameterTuningJobs/7512094338407464960, <google.cloud.aiplatform.jobs.HyperparameterTuningJob object at 0x7f4271c87b10> \n",
      "resource name: projects/547029906128/locations/us-east1/hyperparameterTuningJobs/1049428873130803200, <google.cloud.aiplatform.jobs.HyperparameterTuningJob object at 0x7f4271c87910> \n",
      "resource name: projects/547029906128/locations/us-east1/hyperparameterTuningJobs/5553943294175608832, <google.cloud.aiplatform.jobs.HyperparameterTuningJob object at 0x7f4271c86510> \n",
      "resource name: projects/547029906128/locations/us-east1/hyperparameterTuningJobs/7701245522757025792, <google.cloud.aiplatform.jobs.HyperparameterTuningJob object at 0x7f4271c91510> \n",
      "resource name: projects/547029906128/locations/us-east1/hyperparameterTuningJobs/5809733679261417472, <google.cloud.aiplatform.jobs.HyperparameterTuningJob object at 0x7f4271c2f110> \n",
      "resource name: projects/547029906128/locations/us-east1/hyperparameterTuningJobs/1381921189370265600, <google.cloud.aiplatform.jobs.HyperparameterTuningJob object at 0x7f4271c2fbd0> \n",
      "resource name: projects/547029906128/locations/us-east1/hyperparameterTuningJobs/2420000903479164928, <google.cloud.aiplatform.jobs.HyperparameterTuningJob object at 0x7f4271c2fa10> \n",
      "resource name: projects/547029906128/locations/us-east1/hyperparameterTuningJobs/3073022849447886848, <google.cloud.aiplatform.jobs.HyperparameterTuningJob object at 0x7f4271c91950> \n",
      "resource name: projects/547029906128/locations/us-east1/hyperparameterTuningJobs/767179840234192896, <google.cloud.aiplatform.jobs.HyperparameterTuningJob object at 0x7f4271c86410> \n",
      "resource name: projects/547029906128/locations/us-east1/hyperparameterTuningJobs/4732599312133914624, <google.cloud.aiplatform.jobs.HyperparameterTuningJob object at 0x7f4271c33490> \n",
      "resource name: projects/547029906128/locations/us-east1/hyperparameterTuningJobs/7409989290605674496, <google.cloud.aiplatform.jobs.HyperparameterTuningJob object at 0x7f4271c33950> \n",
      "resource name: projects/547029906128/locations/us-east1/hyperparameterTuningJobs/2798303272178286592, <google.cloud.aiplatform.jobs.HyperparameterTuningJob object at 0x7f4271c87810> \n",
      "resource name: projects/547029906128/locations/us-east1/hyperparameterTuningJobs/5635571037421699072, <google.cloud.aiplatform.jobs.HyperparameterTuningJob object at 0x7f4271c2fa90> \n",
      "resource name: projects/547029906128/locations/us-east1/hyperparameterTuningJobs/1794000555274665984, <google.cloud.aiplatform.jobs.HyperparameterTuningJob object at 0x7f4271c33ed0> \n",
      "resource name: projects/547029906128/locations/us-east1/hyperparameterTuningJobs/7968435644399616000, <google.cloud.aiplatform.jobs.HyperparameterTuningJob object at 0x7f4271c393d0> \n",
      "resource name: projects/547029906128/locations/us-east1/hyperparameterTuningJobs/717640244333117440, <google.cloud.aiplatform.jobs.HyperparameterTuningJob object at 0x7f4271c39950> \n",
      "resource name: projects/547029906128/locations/us-east1/hyperparameterTuningJobs/7828824055951130624, <google.cloud.aiplatform.jobs.HyperparameterTuningJob object at 0x7f4271c2f5d0> \n",
      "resource name: projects/547029906128/locations/us-east1/hyperparameterTuningJobs/8833126772854751232, <google.cloud.aiplatform.jobs.HyperparameterTuningJob object at 0x7f4271cf3850> \n",
      "resource name: projects/547029906128/locations/us-east1/hyperparameterTuningJobs/2465036899752869888, <google.cloud.aiplatform.jobs.HyperparameterTuningJob object at 0x7f4271c39c50> \n",
      "resource name: projects/547029906128/locations/us-east1/hyperparameterTuningJobs/2906248925746823168, <google.cloud.aiplatform.jobs.HyperparameterTuningJob object at 0x7f4271c39dd0> \n",
      "resource name: projects/547029906128/locations/us-east1/hyperparameterTuningJobs/6146588857639895040, <google.cloud.aiplatform.jobs.HyperparameterTuningJob object at 0x7f4271c87b90> \n",
      "resource name: projects/547029906128/locations/us-east1/hyperparameterTuningJobs/9114461012077051904, <google.cloud.aiplatform.jobs.HyperparameterTuningJob object at 0x7f4271c39690> \n",
      "resource name: projects/547029906128/locations/us-east1/hyperparameterTuningJobs/7866963915295424512, <google.cloud.aiplatform.jobs.HyperparameterTuningJob object at 0x7f4271c2f150> \n",
      "resource name: projects/547029906128/locations/us-east1/hyperparameterTuningJobs/9186518606114979840, <google.cloud.aiplatform.jobs.HyperparameterTuningJob object at 0x7f4271c3e410> \n",
      "resource name: projects/547029906128/locations/us-east1/hyperparameterTuningJobs/2329788173443399680, <google.cloud.aiplatform.jobs.HyperparameterTuningJob object at 0x7f4271c3e950> \n",
      "resource name: projects/547029906128/locations/us-east1/hyperparameterTuningJobs/1847903013314756608]\n",
      "1515551434563649536\n",
      "Using endpoint [https://us-east1-aiplatform.googleapis.com/]\n",
      "createTime: '2022-06-08T01:30:32.595929Z'\n",
      "displayName: beer_recom_tuning_20220608_013031\n",
      "endTime: '2022-06-08T01:38:46Z'\n",
      "maxTrialCount: 5\n",
      "name: projects/547029906128/locations/us-east1/hyperparameterTuningJobs/1515551434563649536\n",
      "parallelTrialCount: 5\n",
      "startTime: '2022-06-08T01:30:36Z'\n",
      "state: JOB_STATE_SUCCEEDED\n",
      "studySpec:\n",
      "  metrics:\n",
      "  - goal: MAXIMIZE\n",
      "    metricId: map_at_10\n",
      "  parameters:\n",
      "  - discreteValueSpec:\n",
      "      values:\n",
      "      - 16.0\n",
      "      - 32.0\n",
      "      - 64.0\n",
      "    parameterId: factors\n",
      "  - integerValueSpec:\n",
      "      maxValue: '100'\n",
      "      minValue: '10'\n",
      "    parameterId: iterations\n",
      "    scaleType: UNIT_LINEAR_SCALE\n",
      "  - doubleValueSpec:\n",
      "      maxValue: 0.1\n",
      "      minValue: 0.0001\n",
      "    parameterId: regularization\n",
      "    scaleType: UNIT_LOG_SCALE\n",
      "trialJobSpec:\n",
      "  workerPoolSpecs:\n",
      "  - containerSpec:\n",
      "      imageUri: gcr.io/qwiklabs-asl-04-5e165f533cac/trainer_image\n",
      "    diskSpec:\n",
      "      bootDiskSizeGb: 100\n",
      "      bootDiskType: pd-ssd\n",
      "    machineSpec:\n",
      "      machineType: n1-standard-16\n",
      "    replicaCount: '1'\n",
      "trials:\n",
      "- endTime: '2022-06-08T01:34:11Z'\n",
      "  finalMeasurement:\n",
      "    metrics:\n",
      "    - metricId: map_at_10\n",
      "      value: 0.0854768\n",
      "    stepCount: '1'\n",
      "  id: '1'\n",
      "  parameters:\n",
      "  - parameterId: factors\n",
      "    value: 32\n",
      "  - parameterId: iterations\n",
      "    value: 55\n",
      "  - parameterId: regularization\n",
      "    value: 0.00316228\n",
      "  startTime: '2022-06-08T01:30:42.316353021Z'\n",
      "  state: SUCCEEDED\n",
      "- endTime: '2022-06-08T01:34:52Z'\n",
      "  finalMeasurement:\n",
      "    metrics:\n",
      "    - metricId: map_at_10\n",
      "      value: 0.0821356\n",
      "    stepCount: '1'\n",
      "  id: '2'\n",
      "  parameters:\n",
      "  - parameterId: factors\n",
      "    value: 64\n",
      "  - parameterId: iterations\n",
      "    value: 74\n",
      "  - parameterId: regularization\n",
      "    value: 0.000777048\n",
      "  startTime: '2022-06-08T01:30:42.316541281Z'\n",
      "  state: SUCCEEDED\n",
      "- endTime: '2022-06-08T01:34:47Z'\n",
      "  finalMeasurement:\n",
      "    metrics:\n",
      "    - metricId: map_at_10\n",
      "      value: 0.0855798\n",
      "    stepCount: '1'\n",
      "  id: '3'\n",
      "  parameters:\n",
      "  - parameterId: factors\n",
      "    value: 32\n",
      "  - parameterId: iterations\n",
      "    value: 75\n",
      "  - parameterId: regularization\n",
      "    value: 0.0154753\n",
      "  startTime: '2022-06-08T01:30:42.316594434Z'\n",
      "  state: SUCCEEDED\n",
      "- endTime: '2022-06-08T01:34:17Z'\n",
      "  finalMeasurement:\n",
      "    metrics:\n",
      "    - metricId: map_at_10\n",
      "      value: 0.0852253\n",
      "    stepCount: '1'\n",
      "  id: '4'\n",
      "  parameters:\n",
      "  - parameterId: factors\n",
      "    value: 32\n",
      "  - parameterId: iterations\n",
      "    value: 42\n",
      "  - parameterId: regularization\n",
      "    value: 0.0171471\n",
      "  startTime: '2022-06-08T01:30:42.316640889Z'\n",
      "  state: SUCCEEDED\n",
      "- endTime: '2022-06-08T01:35:19Z'\n",
      "  finalMeasurement:\n",
      "    metrics:\n",
      "    - metricId: map_at_10\n",
      "      value: 0.085629\n",
      "    stepCount: '1'\n",
      "  id: '5'\n",
      "  parameters:\n",
      "  - parameterId: factors\n",
      "    value: 32\n",
      "  - parameterId: iterations\n",
      "    value: 96\n",
      "  - parameterId: regularization\n",
      "    value: 0.0045715\n",
      "  startTime: '2022-06-08T01:30:42.316679140Z'\n",
      "  state: SUCCEEDED\n",
      "updateTime: '2022-06-08T01:39:06.799664Z'\n"
     ]
    }
   ],
   "source": [
    "aiplatform.init(location=\"us-east1\")\n",
    "jobs = aiplatform.HyperparameterTuningJob.list()\n",
    "print(jobs)\n",
    "match = [job for job in jobs if job.display_name == JOB_NAME]\n",
    "tuning_job = match[0] if match else None\n",
    "JOB_NUM = str(tuning_job)[-19:]\n",
    "print(JOB_NUM)\n",
    "!gcloud ai hp-tuning-jobs describe $JOB_NUM --region=us-east1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a960ae-0a31-416e-8e3f-27da59680ca7",
   "metadata": {},
   "source": [
    "### Retrieve HP-tuning results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b5986c-ea52-4548-aa23-b501d7961eb2",
   "metadata": {},
   "source": [
    "After the job completes you can review the results using GCP Console or programmatically using the following functions (note that this code supposes that the metrics that the hyperparameter tuning engine optimizes is maximized): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "76ecb409-fcd2-4868-aef9-398af862f059",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trials(job_name):\n",
    "    #aiplatform.init(location=\"us-east1\")\n",
    "    jobs = aiplatform.HyperparameterTuningJob.list()\n",
    "    match = [job for job in jobs if job.display_name == JOB_NAME]\n",
    "    tuning_job = match[0] if match else None\n",
    "    return tuning_job.trials if tuning_job else None\n",
    "\n",
    "\n",
    "def get_best_trial(trials):\n",
    "    metrics = [trial.final_measurement.metrics[0].value for trial in trials]\n",
    "    best_trial = trials[metrics.index(max(metrics))]\n",
    "    return best_trial\n",
    "\n",
    "\n",
    "def retrieve_best_trial_from_job_name(jobname):\n",
    "    trials = get_trials(jobname)\n",
    "    best_trial = get_best_trial(trials)\n",
    "    return best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9ee2f10-b282-4628-a762-e73751928c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<google.cloud.aiplatform.jobs.HyperparameterTuningJob object at 0x7f4271d20350> \n",
      "resource name: projects/547029906128/locations/us-east1/hyperparameterTuningJobs/1515551434563649536]\n",
      "<google.cloud.aiplatform.jobs.HyperparameterTuningJob object at 0x7f4271d20350> \n",
      "resource name: projects/547029906128/locations/us-east1/hyperparameterTuningJobs/1515551434563649536\n",
      "[id: \"1\"\n",
      "state: SUCCEEDED\n",
      "parameters {\n",
      "  parameter_id: \"factors\"\n",
      "  value {\n",
      "    number_value: 32.0\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameter_id: \"iterations\"\n",
      "  value {\n",
      "    number_value: 55.0\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameter_id: \"regularization\"\n",
      "  value {\n",
      "    number_value: 0.003162277660168379\n",
      "  }\n",
      "}\n",
      "final_measurement {\n",
      "  step_count: 1\n",
      "  metrics {\n",
      "    metric_id: \"map_at_10\"\n",
      "    value: 0.08547677242622731\n",
      "  }\n",
      "}\n",
      "start_time {\n",
      "  seconds: 1654651842\n",
      "  nanos: 316353021\n",
      "}\n",
      "end_time {\n",
      "  seconds: 1654652051\n",
      "}\n",
      ", id: \"2\"\n",
      "state: SUCCEEDED\n",
      "parameters {\n",
      "  parameter_id: \"factors\"\n",
      "  value {\n",
      "    number_value: 64.0\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameter_id: \"iterations\"\n",
      "  value {\n",
      "    number_value: 74.0\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameter_id: \"regularization\"\n",
      "  value {\n",
      "    number_value: 0.0007770478260170782\n",
      "  }\n",
      "}\n",
      "final_measurement {\n",
      "  step_count: 1\n",
      "  metrics {\n",
      "    metric_id: \"map_at_10\"\n",
      "    value: 0.08213556648593943\n",
      "  }\n",
      "}\n",
      "start_time {\n",
      "  seconds: 1654651842\n",
      "  nanos: 316541281\n",
      "}\n",
      "end_time {\n",
      "  seconds: 1654652092\n",
      "}\n",
      ", id: \"3\"\n",
      "state: SUCCEEDED\n",
      "parameters {\n",
      "  parameter_id: \"factors\"\n",
      "  value {\n",
      "    number_value: 32.0\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameter_id: \"iterations\"\n",
      "  value {\n",
      "    number_value: 75.0\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameter_id: \"regularization\"\n",
      "  value {\n",
      "    number_value: 0.015475337143465885\n",
      "  }\n",
      "}\n",
      "final_measurement {\n",
      "  step_count: 1\n",
      "  metrics {\n",
      "    metric_id: \"map_at_10\"\n",
      "    value: 0.08557975682016754\n",
      "  }\n",
      "}\n",
      "start_time {\n",
      "  seconds: 1654651842\n",
      "  nanos: 316594434\n",
      "}\n",
      "end_time {\n",
      "  seconds: 1654652087\n",
      "}\n",
      ", id: \"4\"\n",
      "state: SUCCEEDED\n",
      "parameters {\n",
      "  parameter_id: \"factors\"\n",
      "  value {\n",
      "    number_value: 32.0\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameter_id: \"iterations\"\n",
      "  value {\n",
      "    number_value: 42.0\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameter_id: \"regularization\"\n",
      "  value {\n",
      "    number_value: 0.01714711816532282\n",
      "  }\n",
      "}\n",
      "final_measurement {\n",
      "  step_count: 1\n",
      "  metrics {\n",
      "    metric_id: \"map_at_10\"\n",
      "    value: 0.08522526352524636\n",
      "  }\n",
      "}\n",
      "start_time {\n",
      "  seconds: 1654651842\n",
      "  nanos: 316640889\n",
      "}\n",
      "end_time {\n",
      "  seconds: 1654652057\n",
      "}\n",
      ", id: \"5\"\n",
      "state: SUCCEEDED\n",
      "parameters {\n",
      "  parameter_id: \"factors\"\n",
      "  value {\n",
      "    number_value: 32.0\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameter_id: \"iterations\"\n",
      "  value {\n",
      "    number_value: 96.0\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameter_id: \"regularization\"\n",
      "  value {\n",
      "    number_value: 0.004571501226874493\n",
      "  }\n",
      "}\n",
      "final_measurement {\n",
      "  step_count: 1\n",
      "  metrics {\n",
      "    metric_id: \"map_at_10\"\n",
      "    value: 0.08562903097989699\n",
      "  }\n",
      "}\n",
      "start_time {\n",
      "  seconds: 1654651842\n",
      "  nanos: 316679140\n",
      "}\n",
      "end_time {\n",
      "  seconds: 1654652119\n",
      "}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "jobs = aiplatform.HyperparameterTuningJob.list()\n",
    "match = [job for job in jobs if job.display_name == JOB_NAME]\n",
    "print(match)\n",
    "tuning_job = match[0] if match else None\n",
    "print(tuning_job)\n",
    "print(tuning_job.trials)\n",
    "best_trial = retrieve_best_trial_from_job_name(JOB_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8251541-bf28-4f19-a547-017c53256a24",
   "metadata": {},
   "source": [
    "## Retrain the model with the best hyperparameters\n",
    "\n",
    "You can now retrain the model using the best hyperparameters and using combined training and validation splits as a training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048550b7-20c7-4f1b-be7b-7af1aa50c839",
   "metadata": {},
   "source": [
    "### Configure and run the training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a7f54d14-ad9d-4d94-ac6e-b4ff9e4bb563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-east1-aiplatform.googleapis.com/]\n",
      "CustomJob [projects/547029906128/locations/us-east1/customJobs/8836152628854390784] is submitted successfully.\n",
      "\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai custom-jobs describe projects/547029906128/locations/us-east1/customJobs/8836152628854390784\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai custom-jobs stream-logs projects/547029906128/locations/us-east1/customJobs/8836152628854390784\n",
      "The model will be exported at: gs://qwiklabs-asl-04-5e165f533cac-beer-artifact-store/jobs/JOB_VERTEX_20220608_023049\n"
     ]
    }
   ],
   "source": [
    "FACTORS = int(best_trial.parameters[0].value)\n",
    "ITERATIONS = int(best_trial.parameters[1].value)\n",
    "REGULARIZATION = best_trial.parameters[2].value\n",
    "ISTUNE = False\n",
    "\n",
    "REGION = \"us-east1\"\n",
    "PROJECT_ID = \"qwiklabs-asl-04-5e165f533cac\"\n",
    "ARTIFACT_STORE = f\"gs://{PROJECT_ID}-beer-artifact-store\"\n",
    "DATA_ROOT = os.path.join(ARTIFACT_STORE, \"data\")\n",
    "JOB_DIR_ROOT = os.path.join(ARTIFACT_STORE, \"jobs\")\n",
    "\n",
    "TIMESTAMP = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "JOB_NAME = f\"JOB_VERTEX_{TIMESTAMP}\"\n",
    "JOB_DIR = f\"{JOB_DIR_ROOT}/{JOB_NAME}\"\n",
    "\n",
    "MACHINE_TYPE=\"n1-standard-16\"\n",
    "REPLICA_COUNT=1\n",
    "\n",
    "WORKER_POOL_SPEC = f\"\"\"\\\n",
    "machine-type={MACHINE_TYPE},\\\n",
    "replica-count={REPLICA_COUNT},\\\n",
    "container-image-uri={IMAGE_URI}\\\n",
    "\"\"\"\n",
    "\n",
    "ARGS = f\"\"\"\\\n",
    "--factors={FACTORS},\\\n",
    "--regularization={REGULARIZATION},\\\n",
    "--iterations={ITERATIONS},\\\n",
    "--is_tune={ISTUNE}\n",
    "\"\"\"\n",
    "\n",
    "!gcloud ai custom-jobs create \\\n",
    "  --region={REGION} \\\n",
    "  --display-name={JOB_NAME} \\\n",
    "  --worker-pool-spec={WORKER_POOL_SPEC} \\\n",
    "  --args={ARGS}\n",
    "\n",
    "#!gcloud ai custom-jobs create \\\n",
    "#  --region={REGION} \\\n",
    "#  --display-name={JOB_NAME} \\\n",
    "#  --worker-pool-spec={WORKER_POOL_SPEC} \\\n",
    "\n",
    "print(\"The model will be exported at:\", JOB_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "49f91fb1-0817-49e8-b167-9a084686b4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3821394443777343488\n",
      "Using endpoint [https://us-east1-aiplatform.googleapis.com/]\n",
      "createTime: '2022-06-08T01:42:50.996217Z'\n",
      "displayName: JOB_VERTEX_20220608_014249\n",
      "jobSpec:\n",
      "  workerPoolSpecs:\n",
      "  - containerSpec:\n",
      "      args:\n",
      "      - --factors=32\n",
      "      - --regularization=0.004571501226874493\n",
      "      - --iterations=96\n",
      "      - --is_tune=False\n",
      "      imageUri: gcr.io/qwiklabs-asl-04-5e165f533cac/trainer_image:latest\n",
      "    diskSpec:\n",
      "      bootDiskSizeGb: 100\n",
      "      bootDiskType: pd-ssd\n",
      "    machineSpec:\n",
      "      machineType: n1-standard-16\n",
      "    replicaCount: '1'\n",
      "name: projects/547029906128/locations/us-east1/customJobs/3821394443777343488\n",
      "startTime: '2022-06-08T01:42:51.215900Z'\n",
      "state: JOB_STATE_PENDING\n",
      "updateTime: '2022-06-08T01:42:51.535750Z'\n"
     ]
    }
   ],
   "source": [
    "#jobs = aiplatform.HyperparameterTuningJob.list()\n",
    "jobs = aiplatform.CustomJob.list()\n",
    "match = [job for job in jobs if job.display_name == JOB_NAME]\n",
    "tuning_job = match[0] if match else None\n",
    "JOB_NUM = str(tuning_job)[-19:]\n",
    "print(JOB_NUM)\n",
    "!gcloud ai custom-jobs describe projects/547029906128/locations/us-east1/customJobs/$JOB_NUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7494347-fe21-4076-a9d9-bd45790853c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m93"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
