{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3802510a-b813-40c2-a77e-906e191df9d2",
   "metadata": {},
   "source": [
    "## Configure environment settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d80c27-6e4d-4d55-8e5c-fc8fa40020bf",
   "metadata": {},
   "source": [
    "Set location paths, connections strings, and other environment settings. Make sure to update   `REGION`, and `ARTIFACT_STORE`  with the settings reflecting your lab environment. \n",
    "\n",
    "- `REGION` - the compute region for Vertex AI Training and Prediction\n",
    "- `ARTIFACT_STORE` - A GCS bucket in the created in the same region."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9d55d2-f592-40aa-af7d-9926ae0fba1b",
   "metadata": {},
   "source": [
    "Containerized Training Cloud Serving\n",
    "- `Phase 1` - (Before ML Pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "28d72e95-efe9-450f-a629-1a53d51e4b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "497ee2f8-6173-467b-b80a-f63ea1ce0bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = \"us-east1\"\n",
    "\n",
    "PROJECT_ID = !(gcloud config get-value core/project)\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "\n",
    "ARTIFACT_STORE = f\"gs://{PROJECT_ID}-beer-artifact-store\"\n",
    "\n",
    "DATA_ROOT = f\"{ARTIFACT_STORE}/data\"\n",
    "JOB_DIR_ROOT = f\"{ARTIFACT_STORE}/jobs\"\n",
    "TRAINING_FILE_PATH = f\"{DATA_ROOT}/train.parquet\"\n",
    "VALIDATION_FILE_PATH = f\"{DATA_ROOT}/valid.parquet\"\n",
    "API_ENDPOINT = f\"{REGION}-aiplatform.googleapis.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9c4049d0-e395-4c17-8b28-011316630e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"JOB_DIR_ROOT\"] = JOB_DIR_ROOT\n",
    "os.environ[\"TRAINING_FILE_PATH\"] = TRAINING_FILE_PATH\n",
    "os.environ[\"VALIDATION_FILE_PATH\"] = VALIDATION_FILE_PATH\n",
    "os.environ[\"PROJECT_ID\"] = PROJECT_ID\n",
    "os.environ[\"REGION\"] = REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9cbe53f6-febd-492d-8d85-a65ee900c877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://qwiklabs-asl-04-5e165f533cac-beer-artifact-store/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls | grep ^{ARTIFACT_STORE}/$ || gsutil mb -l {REGION} {ARTIFACT_STORE}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a54a91-79ad-4e10-a3cf-fd3aa1d789cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Package the script into a docker image.\n",
    "\n",
    "Notice that we are installing specific versions of `scikit-learn` and `pandas` in the training image. This is done to make sure that the training runtime in the training container is aligned with the serving runtime in the serving container. \n",
    "\n",
    "Make sure to update the URI for the base image so that it points to your project's **Container Registry**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9a7be472-cff7-452e-9337-1c169823ef5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_APP_FOLDER = \"training_app\"\n",
    "os.makedirs(TRAINING_APP_FOLDER, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6caa7193-c966-4aa2-a2ee-9833857b852b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting training_app/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile {TRAINING_APP_FOLDER}/Dockerfile\n",
    "\n",
    "FROM gcr.io/deeplearning-platform-release/base-cpu\n",
    "RUN pip install -U fire cloudml-hypertune implicit\n",
    "WORKDIR /app\n",
    "COPY train.py .\n",
    "\n",
    "ENTRYPOINT [\"python\", \"train.py\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "70e86dde-f309-4735-84c8-12ff69d08658",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_NAME = \"trainer_image\"\n",
    "IMAGE_TAG = \"latest\"\n",
    "IMAGE_URI = f\"gcr.io/{PROJECT_ID}/{IMAGE_NAME}:{IMAGE_TAG}\"\n",
    "\n",
    "os.environ[\"IMAGE_URI\"] = IMAGE_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "cfd37de2-dab7-45a3-b944-da4c4c7c085f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 4 file(s) totalling 15.7 KiB before compression.\n",
      "Uploading tarball of [training_app] to [gs://qwiklabs-asl-04-5e165f533cac_cloudbuild/source/1654594411.17675-78d8543396d14197b1d0784745295a5d.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/qwiklabs-asl-04-5e165f533cac/locations/global/builds/9e6c9d34-03dc-4794-bf75-f9ac09fe55a3].\n",
      "Logs are available at [https://console.cloud.google.com/cloud-build/builds/9e6c9d34-03dc-4794-bf75-f9ac09fe55a3?project=547029906128].\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"9e6c9d34-03dc-4794-bf75-f9ac09fe55a3\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://qwiklabs-asl-04-5e165f533cac_cloudbuild/source/1654594411.17675-78d8543396d14197b1d0784745295a5d.tgz#1654594411391223\n",
      "Copying gs://qwiklabs-asl-04-5e165f533cac_cloudbuild/source/1654594411.17675-78d8543396d14197b1d0784745295a5d.tgz#1654594411391223...\n",
      "/ [1 files][  3.1 KiB/  3.1 KiB]                                                \n",
      "Operation completed over 1 objects/3.1 KiB.\n",
      "BUILD\n",
      "Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Sending build context to Docker daemon  20.99kB\n",
      "Step 1/5 : FROM gcr.io/deeplearning-platform-release/base-cpu\n",
      "latest: Pulling from deeplearning-platform-release/base-cpu\n",
      "d5fd17ec1767: Pulling fs layer\n",
      "adb65a4cea80: Pulling fs layer\n",
      "4f4fb700ef54: Pulling fs layer\n",
      "4ae9dce86192: Pulling fs layer\n",
      "3c97dd6fc917: Pulling fs layer\n",
      "9a421421a9c6: Pulling fs layer\n",
      "8c3aa27ae5ff: Pulling fs layer\n",
      "ed3dcc4cfb6c: Pulling fs layer\n",
      "3debde04b610: Pulling fs layer\n",
      "f5164395e213: Pulling fs layer\n",
      "7c0e9eccc936: Pulling fs layer\n",
      "d78c60a0dcbe: Pulling fs layer\n",
      "ff2acd98ca45: Pulling fs layer\n",
      "a11a78983f17: Pulling fs layer\n",
      "6b33fb6f0d3a: Pulling fs layer\n",
      "3293f65cfcaa: Pulling fs layer\n",
      "aa9e1ad00162: Pulling fs layer\n",
      "9c25ce1cf557: Pulling fs layer\n",
      "4ae9dce86192: Waiting\n",
      "3c97dd6fc917: Waiting\n",
      "9a421421a9c6: Waiting\n",
      "8c3aa27ae5ff: Waiting\n",
      "ed3dcc4cfb6c: Waiting\n",
      "3debde04b610: Waiting\n",
      "f5164395e213: Waiting\n",
      "7c0e9eccc936: Waiting\n",
      "d78c60a0dcbe: Waiting\n",
      "ff2acd98ca45: Waiting\n",
      "a11a78983f17: Waiting\n",
      "6b33fb6f0d3a: Waiting\n",
      "3293f65cfcaa: Waiting\n",
      "aa9e1ad00162: Waiting\n",
      "9c25ce1cf557: Waiting\n",
      "4f4fb700ef54: Verifying Checksum\n",
      "4f4fb700ef54: Download complete\n",
      "adb65a4cea80: Verifying Checksum\n",
      "adb65a4cea80: Download complete\n",
      "d5fd17ec1767: Verifying Checksum\n",
      "d5fd17ec1767: Download complete\n",
      "9a421421a9c6: Download complete\n",
      "8c3aa27ae5ff: Verifying Checksum\n",
      "8c3aa27ae5ff: Download complete\n",
      "3c97dd6fc917: Verifying Checksum\n",
      "3c97dd6fc917: Download complete\n",
      "ed3dcc4cfb6c: Verifying Checksum\n",
      "ed3dcc4cfb6c: Download complete\n",
      "3debde04b610: Verifying Checksum\n",
      "3debde04b610: Download complete\n",
      "f5164395e213: Verifying Checksum\n",
      "f5164395e213: Download complete\n",
      "7c0e9eccc936: Verifying Checksum\n",
      "7c0e9eccc936: Download complete\n",
      "d78c60a0dcbe: Verifying Checksum\n",
      "d78c60a0dcbe: Download complete\n",
      "ff2acd98ca45: Verifying Checksum\n",
      "ff2acd98ca45: Download complete\n",
      "a11a78983f17: Verifying Checksum\n",
      "a11a78983f17: Download complete\n",
      "6b33fb6f0d3a: Verifying Checksum\n",
      "6b33fb6f0d3a: Download complete\n",
      "3293f65cfcaa: Verifying Checksum\n",
      "3293f65cfcaa: Download complete\n",
      "9c25ce1cf557: Verifying Checksum\n",
      "9c25ce1cf557: Download complete\n",
      "4ae9dce86192: Verifying Checksum\n",
      "4ae9dce86192: Download complete\n",
      "d5fd17ec1767: Pull complete\n",
      "adb65a4cea80: Pull complete\n",
      "4f4fb700ef54: Pull complete\n",
      "aa9e1ad00162: Verifying Checksum\n",
      "aa9e1ad00162: Download complete\n",
      "4ae9dce86192: Pull complete\n",
      "3c97dd6fc917: Pull complete\n",
      "9a421421a9c6: Pull complete\n",
      "8c3aa27ae5ff: Pull complete\n",
      "ed3dcc4cfb6c: Pull complete\n",
      "3debde04b610: Pull complete\n",
      "f5164395e213: Pull complete\n",
      "7c0e9eccc936: Pull complete\n",
      "d78c60a0dcbe: Pull complete\n",
      "ff2acd98ca45: Pull complete\n",
      "a11a78983f17: Pull complete\n",
      "6b33fb6f0d3a: Pull complete\n",
      "3293f65cfcaa: Pull complete\n",
      "aa9e1ad00162: Pull complete\n",
      "9c25ce1cf557: Pull complete\n",
      "Digest: sha256:8ad8673b3dcf0645737cc7adf32c0bacec683532ffdeae26fde760998c262972\n",
      "Status: Downloaded newer image for gcr.io/deeplearning-platform-release/base-cpu:latest\n",
      " ---> 4d10005d4e6f\n",
      "Step 2/5 : RUN pip install -U fire cloudml-hypertune implicit\n",
      " ---> Running in cba6bb12993d\n",
      "Collecting fire\n",
      "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 87.7/87.7 kB 2.4 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting cloudml-hypertune\n",
      "  Downloading cloudml-hypertune-0.1.0.dev6.tar.gz (3.2 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting implicit\n",
      "  Downloading implicit-0.5.2-cp37-cp37m-manylinux2014_x86_64.whl (18.5 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.5/18.5 MB 34.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from fire) (1.16.0)\n",
      "Collecting termcolor\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from implicit) (1.19.5)\n",
      "Requirement already satisfied: scipy>=0.16 in /opt/conda/lib/python3.7/site-packages (from implicit) (1.7.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from implicit) (4.64.0)\n",
      "Building wheels for collected packages: fire, cloudml-hypertune, termcolor\n",
      "  Building wheel for fire (setup.py): started\n",
      "  Building wheel for fire (setup.py): finished with status 'done'\n",
      "  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115942 sha256=13ba492bbe7f2bd17d2c0e1f094a34a788327d631412b4b950f55d7803ff164a\n",
      "  Stored in directory: /root/.cache/pip/wheels/8a/67/fb/2e8a12fa16661b9d5af1f654bd199366799740a85c64981226\n",
      "  Building wheel for cloudml-hypertune (setup.py): started\n",
      "  Building wheel for cloudml-hypertune (setup.py): finished with status 'done'\n",
      "  Created wheel for cloudml-hypertune: filename=cloudml_hypertune-0.1.0.dev6-py2.py3-none-any.whl size=3987 sha256=058cdcf43cf1c2a7f910e229651a6ca5a8582bbe367f80f60e76ed34e1af8bdc\n",
      "  Stored in directory: /root/.cache/pip/wheels/a7/ff/87/e7bed0c2741fe219b3d6da67c2431d7f7fedb183032e00f81e\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4848 sha256=1581409c33e81b1a2fb4c1a153e2e537ab5dcd3e8e74369396751b555e2a3d7b\n",
      "  Stored in directory: /root/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
      "Successfully built fire cloudml-hypertune termcolor\n",
      "Installing collected packages: termcolor, cloudml-hypertune, fire, implicit\n",
      "Successfully installed cloudml-hypertune-0.1.0.dev6 fire-0.4.0 implicit-0.5.2 termcolor-1.1.0\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRemoving intermediate container cba6bb12993d\n",
      " ---> cd247c9dd052\n",
      "Step 3/5 : WORKDIR /app\n",
      " ---> Running in 7d79fc09bef3\n",
      "Removing intermediate container 7d79fc09bef3\n",
      " ---> 77be3f97574a\n",
      "Step 4/5 : COPY train.py .\n",
      " ---> 6950a31c7169\n",
      "Step 5/5 : ENTRYPOINT [\"python\", \"train.py\"]\n",
      " ---> Running in 67dd452b4b71\n",
      "Removing intermediate container 67dd452b4b71\n",
      " ---> fadd43c0d0e7\n",
      "Successfully built fadd43c0d0e7\n",
      "Successfully tagged gcr.io/qwiklabs-asl-04-5e165f533cac/trainer_image:latest\n",
      "PUSH\n",
      "Pushing gcr.io/qwiklabs-asl-04-5e165f533cac/trainer_image:latest\n",
      "The push refers to repository [gcr.io/qwiklabs-asl-04-5e165f533cac/trainer_image]\n",
      "67ab3f0650bd: Preparing\n",
      "54637622e46b: Preparing\n",
      "84bf6fa6c023: Preparing\n",
      "a74d37ed3ebe: Preparing\n",
      "358d0c97e748: Preparing\n",
      "a72622d8d85c: Preparing\n",
      "a44ab01c5179: Preparing\n",
      "5dc3e696ff5b: Preparing\n",
      "614f43fff4a9: Preparing\n",
      "ae2d9c14a32d: Preparing\n",
      "7d7cd198ee7d: Preparing\n",
      "186b46a1d19e: Preparing\n",
      "ac6ab83c1c63: Preparing\n",
      "c8e5c31d7bf8: Preparing\n",
      "3e7b03bffb47: Preparing\n",
      "cebed4d6cdf8: Preparing\n",
      "5f70bf18a086: Preparing\n",
      "8320c4cf558f: Preparing\n",
      "67fe02a0cfc8: Preparing\n",
      "5f70bf18a086: Preparing\n",
      "65f26f75faab: Preparing\n",
      "bf8cedc62fb3: Preparing\n",
      "186b46a1d19e: Waiting\n",
      "ac6ab83c1c63: Waiting\n",
      "c8e5c31d7bf8: Waiting\n",
      "3e7b03bffb47: Waiting\n",
      "cebed4d6cdf8: Waiting\n",
      "5f70bf18a086: Waiting\n",
      "8320c4cf558f: Waiting\n",
      "67fe02a0cfc8: Waiting\n",
      "65f26f75faab: Waiting\n",
      "bf8cedc62fb3: Waiting\n",
      "a72622d8d85c: Waiting\n",
      "a44ab01c5179: Waiting\n",
      "5dc3e696ff5b: Waiting\n",
      "614f43fff4a9: Waiting\n",
      "ae2d9c14a32d: Waiting\n",
      "7d7cd198ee7d: Waiting\n",
      "a74d37ed3ebe: Layer already exists\n",
      "358d0c97e748: Layer already exists\n",
      "a44ab01c5179: Layer already exists\n",
      "a72622d8d85c: Layer already exists\n",
      "5dc3e696ff5b: Layer already exists\n",
      "614f43fff4a9: Layer already exists\n",
      "ae2d9c14a32d: Layer already exists\n",
      "7d7cd198ee7d: Layer already exists\n",
      "186b46a1d19e: Layer already exists\n",
      "c8e5c31d7bf8: Layer already exists\n",
      "ac6ab83c1c63: Layer already exists\n",
      "3e7b03bffb47: Layer already exists\n",
      "cebed4d6cdf8: Layer already exists\n",
      "8320c4cf558f: Layer already exists\n",
      "5f70bf18a086: Layer already exists\n",
      "67fe02a0cfc8: Layer already exists\n",
      "65f26f75faab: Layer already exists\n",
      "bf8cedc62fb3: Layer already exists\n",
      "54637622e46b: Pushed\n",
      "67ab3f0650bd: Pushed\n",
      "84bf6fa6c023: Pushed\n",
      "latest: digest: sha256:ba5e5538a343fb054cbc79d88538d2f79da3afe4f1d51c11adf57f8c41e90dda size: 4913\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                                     IMAGES                                                       STATUS\n",
      "9e6c9d34-03dc-4794-bf75-f9ac09fe55a3  2022-06-07T09:33:31+00:00  2M10S     gs://qwiklabs-asl-04-5e165f533cac_cloudbuild/source/1654594411.17675-78d8543396d14197b1d0784745295a5d.tgz  gcr.io/qwiklabs-asl-04-5e165f533cac/trainer_image (+1 more)  SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!gcloud builds submit --tag $IMAGE_URI $TRAINING_APP_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df893958-0b4b-4427-bc40-afb59dce5e41",
   "metadata": {},
   "source": [
    "## Submit an Vertex AI hyperparameter tuning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6af82820-d836-4fce-baa8-a046adef2c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTAMP = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "JOB_NAME = f\"beer_recom_tuning_{TIMESTAMP}\"\n",
    "JOB_DIR = f\"{JOB_DIR_ROOT}/{JOB_NAME}\"\n",
    "\n",
    "os.environ[\"JOB_NAME\"] = JOB_NAME\n",
    "os.environ[\"JOB_DIR\"] = JOB_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "045e6257-aa09-442e-bfab-79fe39378180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOB_NAME: beer_recom_tuning_20220607_093545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-east1-aiplatform.googleapis.com/]\n",
      "Hyperparameter tuning job [1381921189370265600] submitted successfully.\n",
      "\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai hp-tuning-jobs describe 1381921189370265600 --region=us-east1\n",
      "\n",
      "Job State: JOB_STATE_PENDING\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "CONFIG_YAML=config.yaml\n",
    "\n",
    "gcloud ai hp-tuning-jobs create \\\n",
    "    --region=$REGION \\\n",
    "    --display-name=$JOB_NAME \\\n",
    "    --config=$CONFIG_YAML \\\n",
    "    --max-trial-count=5 \\\n",
    "    --parallel-trial-count=5\n",
    "\n",
    "echo \"JOB_NAME: $JOB_NAME\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "449b597e-a2ef-46a9-bfb5-f5b30d5d5fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1381921189370265600\n",
      "Using endpoint [https://us-east1-aiplatform.googleapis.com/]\n",
      "createTime: '2022-06-07T09:35:46.720471Z'\n",
      "displayName: beer_recom_tuning_20220607_093545\n",
      "maxTrialCount: 5\n",
      "name: projects/547029906128/locations/us-east1/hyperparameterTuningJobs/1381921189370265600\n",
      "parallelTrialCount: 5\n",
      "startTime: '2022-06-07T09:35:46.868390Z'\n",
      "state: JOB_STATE_QUEUED\n",
      "studySpec:\n",
      "  metrics:\n",
      "  - goal: MAXIMIZE\n",
      "    metricId: map_at_10\n",
      "  parameters:\n",
      "  - discreteValueSpec:\n",
      "      values:\n",
      "      - 16.0\n",
      "      - 32.0\n",
      "      - 64.0\n",
      "      - 128.0\n",
      "    parameterId: factors\n",
      "  - integerValueSpec:\n",
      "      maxValue: '100'\n",
      "      minValue: '10'\n",
      "    parameterId: iterations\n",
      "    scaleType: UNIT_LINEAR_SCALE\n",
      "  - doubleValueSpec:\n",
      "      maxValue: 0.1\n",
      "      minValue: 0.0001\n",
      "    parameterId: regularization\n",
      "    scaleType: UNIT_LOG_SCALE\n",
      "trialJobSpec:\n",
      "  workerPoolSpecs:\n",
      "  - containerSpec:\n",
      "      imageUri: gcr.io/qwiklabs-asl-04-5e165f533cac/trainer_image\n",
      "    diskSpec:\n",
      "      bootDiskSizeGb: 100\n",
      "      bootDiskType: pd-ssd\n",
      "    machineSpec:\n",
      "      machineType: n1-standard-16\n",
      "    replicaCount: '1'\n",
      "updateTime: '2022-06-07T09:35:47.125914Z'\n"
     ]
    }
   ],
   "source": [
    "jobs = aiplatform.HyperparameterTuningJob.list()\n",
    "match = [job for job in jobs if job.display_name == JOB_NAME]\n",
    "tuning_job = match[0] if match else None\n",
    "JOB_NUM = str(tuning_job)[-19:]\n",
    "print(JOB_NUM)\n",
    "!gcloud ai hp-tuning-jobs describe $JOB_NUM --region=us-east1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a960ae-0a31-416e-8e3f-27da59680ca7",
   "metadata": {},
   "source": [
    "### Retrieve HP-tuning results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b5986c-ea52-4548-aa23-b501d7961eb2",
   "metadata": {},
   "source": [
    "After the job completes you can review the results using GCP Console or programmatically using the following functions (note that this code supposes that the metrics that the hyperparameter tuning engine optimizes is maximized): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "76ecb409-fcd2-4868-aef9-398af862f059",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trials(job_name):\n",
    "    #aiplatform.init(location=\"us-east1\")\n",
    "    jobs = aiplatform.HyperparameterTuningJob.list()\n",
    "    match = [job for job in jobs if job.display_name == JOB_NAME]\n",
    "    tuning_job = match[0] if match else None\n",
    "    return tuning_job.trials if tuning_job else None\n",
    "\n",
    "\n",
    "def get_best_trial(trials):\n",
    "    metrics = [trial.final_measurement.metrics[0].value for trial in trials]\n",
    "    best_trial = trials[metrics.index(max(metrics))]\n",
    "    return best_trial\n",
    "\n",
    "\n",
    "def retrieve_best_trial_from_job_name(jobname):\n",
    "    trials = get_trials(jobname)\n",
    "    best_trial = get_best_trial(trials)\n",
    "    return best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b9ee2f10-b282-4628-a762-e73751928c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<google.cloud.aiplatform.jobs.HyperparameterTuningJob object at 0x7f0df9745590> \n",
      "resource name: projects/547029906128/locations/us-east1/hyperparameterTuningJobs/1381921189370265600]\n",
      "<google.cloud.aiplatform.jobs.HyperparameterTuningJob object at 0x7f0df9745590> \n",
      "resource name: projects/547029906128/locations/us-east1/hyperparameterTuningJobs/1381921189370265600\n",
      "[id: \"1\"\n",
      "state: INFEASIBLE\n",
      "parameters {\n",
      "  parameter_id: \"factors\"\n",
      "  value {\n",
      "    number_value: 64.0\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameter_id: \"iterations\"\n",
      "  value {\n",
      "    number_value: 55.0\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameter_id: \"regularization\"\n",
      "  value {\n",
      "    number_value: 0.003162277660168379\n",
      "  }\n",
      "}\n",
      "start_time {\n",
      "  seconds: 1654594556\n",
      "  nanos: 21423181\n",
      "}\n",
      "end_time {\n",
      "  seconds: 1654594654\n",
      "}\n",
      ", id: \"2\"\n",
      "state: INFEASIBLE\n",
      "parameters {\n",
      "  parameter_id: \"factors\"\n",
      "  value {\n",
      "    number_value: 32.0\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameter_id: \"iterations\"\n",
      "  value {\n",
      "    number_value: 36.0\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameter_id: \"regularization\"\n",
      "  value {\n",
      "    number_value: 0.013960023587135564\n",
      "  }\n",
      "}\n",
      "start_time {\n",
      "  seconds: 1654594556\n",
      "  nanos: 21541430\n",
      "}\n",
      "end_time {\n",
      "  seconds: 1654594659\n",
      "}\n",
      ", id: \"3\"\n",
      "state: INFEASIBLE\n",
      "parameters {\n",
      "  parameter_id: \"factors\"\n",
      "  value {\n",
      "    number_value: 32.0\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameter_id: \"iterations\"\n",
      "  value {\n",
      "    number_value: 76.0\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameter_id: \"regularization\"\n",
      "  value {\n",
      "    number_value: 0.0006484322348459698\n",
      "  }\n",
      "}\n",
      "start_time {\n",
      "  seconds: 1654594556\n",
      "  nanos: 21573440\n",
      "}\n",
      "end_time {\n",
      "  seconds: 1654594684\n",
      "}\n",
      ", id: \"4\"\n",
      "state: INFEASIBLE\n",
      "parameters {\n",
      "  parameter_id: \"factors\"\n",
      "  value {\n",
      "    number_value: 32.0\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameter_id: \"iterations\"\n",
      "  value {\n",
      "    number_value: 50.0\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameter_id: \"regularization\"\n",
      "  value {\n",
      "    number_value: 0.0026288213135381923\n",
      "  }\n",
      "}\n",
      "start_time {\n",
      "  seconds: 1654594556\n",
      "  nanos: 21598918\n",
      "}\n",
      "end_time {\n",
      "  seconds: 1654594686\n",
      "}\n",
      ", id: \"5\"\n",
      "state: INFEASIBLE\n",
      "parameters {\n",
      "  parameter_id: \"factors\"\n",
      "  value {\n",
      "    number_value: 32.0\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameter_id: \"iterations\"\n",
      "  value {\n",
      "    number_value: 61.0\n",
      "  }\n",
      "}\n",
      "parameters {\n",
      "  parameter_id: \"regularization\"\n",
      "  value {\n",
      "    number_value: 0.003872532621731388\n",
      "  }\n",
      "}\n",
      "start_time {\n",
      "  seconds: 1654594556\n",
      "  nanos: 21625921\n",
      "}\n",
      "end_time {\n",
      "  seconds: 1654594655\n",
      "}\n",
      "]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index (0) out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2091326/1284063841.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuning_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuning_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mbest_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretrieve_best_trial_from_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJOB_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_2091326/1790206546.py\u001b[0m in \u001b[0;36mretrieve_best_trial_from_job_name\u001b[0;34m(jobname)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mretrieve_best_trial_from_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjobname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mtrials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjobname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mbest_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_best_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbest_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2091326/1790206546.py\u001b[0m in \u001b[0;36mget_best_trial\u001b[0;34m(trials)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_best_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_measurement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrial\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mbest_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbest_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2091326/1790206546.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_best_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_measurement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrial\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mbest_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbest_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/proto/marshal/collections/repeated.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_marshal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pb_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index (0) out of range"
     ]
    }
   ],
   "source": [
    "jobs = aiplatform.HyperparameterTuningJob.list()\n",
    "match = [job for job in jobs if job.display_name == JOB_NAME]\n",
    "print(match)\n",
    "tuning_job = match[0] if match else None\n",
    "print(tuning_job)\n",
    "print(tuning_job.trials)\n",
    "best_trial = retrieve_best_trial_from_job_name(JOB_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8251541-bf28-4f19-a547-017c53256a24",
   "metadata": {},
   "source": [
    "## Retrain the model with the best hyperparameters\n",
    "\n",
    "You can now retrain the model using the best hyperparameters and using combined training and validation splits as a training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048550b7-20c7-4f1b-be7b-7af1aa50c839",
   "metadata": {},
   "source": [
    "### Configure and run the training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a7f54d14-ad9d-4d94-ac6e-b4ff9e4bb563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-east1-aiplatform.googleapis.com/]\n",
      "CustomJob [projects/547029906128/locations/us-east1/customJobs/1535043576700862464] is submitted successfully.\n",
      "\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai custom-jobs describe projects/547029906128/locations/us-east1/customJobs/1535043576700862464\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai custom-jobs stream-logs projects/547029906128/locations/us-east1/customJobs/1535043576700862464\n",
      "The model will be exported at: gs://qwiklabs-asl-04-5e165f533cac-beer-artifact-store/jobs/JOB_VERTEX_20220607_094936\n"
     ]
    }
   ],
   "source": [
    "FACTORS = int(best_trial.parameters[0].value)\n",
    "ITERATIONS = int(best_trial.parameters[1].value)\n",
    "REGULARIZATION = best_trial.parameters[2].value\n",
    "ISTUNE = False\n",
    "\n",
    "REGION = \"us-east1\"\n",
    "PROJECT_ID = \"qwiklabs-asl-04-5e165f533cac\"\n",
    "ARTIFACT_STORE = f\"gs://{PROJECT_ID}-beer-artifact-store\"\n",
    "DATA_ROOT = os.path.join(ARTIFACT_STORE, \"data\")\n",
    "JOB_DIR_ROOT = os.path.join(ARTIFACT_STORE, \"jobs\")\n",
    "\n",
    "TIMESTAMP = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "JOB_NAME = f\"JOB_VERTEX_{TIMESTAMP}\"\n",
    "JOB_DIR = f\"{JOB_DIR_ROOT}/{JOB_NAME}\"\n",
    "\n",
    "MACHINE_TYPE=\"n1-standard-16\"\n",
    "REPLICA_COUNT=1\n",
    "\n",
    "WORKER_POOL_SPEC = f\"\"\"\\\n",
    "machine-type={MACHINE_TYPE},\\\n",
    "replica-count={REPLICA_COUNT},\\\n",
    "container-image-uri={IMAGE_URI}\\\n",
    "\"\"\"\n",
    "\n",
    "ARGS = f\"\"\"\\\n",
    "--factors={FACTORS},\\\n",
    "--regularization={REGULARIZATION},\\\n",
    "--iterations={ITERATIONS},\\\n",
    "--is_tune={ISTUNE}\n",
    "\"\"\"\n",
    "\n",
    "!gcloud ai custom-jobs create \\\n",
    "  --region={REGION} \\\n",
    "  --display-name={JOB_NAME} \\\n",
    "  --worker-pool-spec={WORKER_POOL_SPEC} \\\n",
    "  --args={ARGS}\n",
    "\n",
    "#!gcloud ai custom-jobs create \\\n",
    "#  --region={REGION} \\\n",
    "#  --display-name={JOB_NAME} \\\n",
    "#  --worker-pool-spec={WORKER_POOL_SPEC} \\\n",
    "\n",
    "print(\"The model will be exported at:\", JOB_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "49f91fb1-0817-49e8-b167-9a084686b4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1535043576700862464\n",
      "Using endpoint [https://us-east1-aiplatform.googleapis.com/]\n",
      "createTime: '2022-06-07T09:49:37.283054Z'\n",
      "displayName: JOB_VERTEX_20220607_094936\n",
      "jobSpec:\n",
      "  workerPoolSpecs:\n",
      "  - containerSpec:\n",
      "      args:\n",
      "      - --factors=32\n",
      "      - --regularization=0.0007930078893541997\n",
      "      - --iterations=100\n",
      "      - --is_tune=False\n",
      "      imageUri: gcr.io/qwiklabs-asl-04-5e165f533cac/trainer_image:latest\n",
      "    diskSpec:\n",
      "      bootDiskSizeGb: 100\n",
      "      bootDiskType: pd-ssd\n",
      "    machineSpec:\n",
      "      machineType: n1-standard-16\n",
      "    replicaCount: '1'\n",
      "name: projects/547029906128/locations/us-east1/customJobs/1535043576700862464\n",
      "startTime: '2022-06-07T09:49:37.481925Z'\n",
      "state: JOB_STATE_PENDING\n",
      "updateTime: '2022-06-07T09:49:37.716216Z'\n"
     ]
    }
   ],
   "source": [
    "#jobs = aiplatform.HyperparameterTuningJob.list()\n",
    "jobs = aiplatform.CustomJob.list()\n",
    "match = [job for job in jobs if job.display_name == JOB_NAME]\n",
    "tuning_job = match[0] if match else None\n",
    "JOB_NUM = str(tuning_job)[-19:]\n",
    "print(JOB_NUM)\n",
    "!gcloud ai custom-jobs describe projects/547029906128/locations/us-east1/customJobs/$JOB_NUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7494347-fe21-4076-a9d9-bd45790853c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m93"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
