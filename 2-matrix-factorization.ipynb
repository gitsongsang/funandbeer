{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17309866-6701-49d6-a539-2a29026acf7a",
   "metadata": {},
   "source": [
    "# Matrix Factorization\n",
    "\n",
    "The first model to compare with baseline is matrix factorization. Since we need to train implicit data, we consider Alternating Least Squares (ALS) as MF model which simple and truely competitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "66356a8c-3ef5-48e0-9d0a-013be87a05a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from scipy import sparse\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from utils.metrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25f2da9-26c2-42b4-a048-be379337bff1",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "08f8a6c9-fea7-48a0-9d93-ebd90ef62e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(\"./data/train.parquet\")\n",
    "valid = pd.read_parquet(\"./data/valid.parquet\")\n",
    "test = pd.read_parquet(\"./data/test.parquet\")\n",
    "most_common_beers = pd.read_parquet(\"./data/most_common_beers.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c74c547-e619-4776-bf9b-c11c917ba8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_users = train[\"review_profilename\"].unique()\n",
    "valid_users = valid[\"review_profilename\"].unique()\n",
    "test_users = test[\"review_profilename\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "5231c7ad-fa7c-43b9-8cec-b79af96ebcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_topk = most_common_beers[:10][\"beer_name\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8e15e98-a8c1-4897-80d0-7ba1e1873a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/user_mapper.dict\", \"rb\") as f:\n",
    "    user_mapper = pickle.load(f)\n",
    "with open(\"./data/item_mapper.dict\", \"rb\") as f:\n",
    "    item_mapper = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88e1ab74-d6fa-44ac-a446-6ba112e5d67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mat = np.zeros((len(user_mapper), len(item_mapper)))\n",
    "valid_mat = np.zeros((len(user_mapper), len(item_mapper)))\n",
    "test_mat = np.zeros((len(user_mapper), len(item_mapper)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1db7304-3dbe-454d-a71e-6141197d2b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92b410945f0643c69a7f22d75c854be9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1022381 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c87f0d00abba4cee803a00fa4872c6a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/220993 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "687b03878e2549cab5a6300adf7ea0b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/222265 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for _, user, item, rating in tqdm(train.itertuples(), total=len(train)):\n",
    "    train_mat[user, item] = 1\n",
    "\n",
    "for _, user, item, rating in tqdm(valid.itertuples(), total=len(valid)):\n",
    "    valid_mat[user, item] = 1\n",
    "\n",
    "for _, user, item, rating in tqdm(test.itertuples(), total=len(test)):\n",
    "    test_mat[user, item] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae39350-f51f-4cd5-8454-9b259d8a82bd",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106049aa-2eba-49c0-85b3-66a28dc7d490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(\n",
    "    user_ids: np.ndarray,\n",
    "    train_mat: sparse.csr_matrix,\n",
    "    model: AlternatingLeastSquares,\n",
    "    popular_items: list,\n",
    "    top_k: int,\n",
    ") -> np.ndarray:\n",
    "    # Make recommendations based on the model\n",
    "    rec = model.recommend(\n",
    "        user_ids, train_mat[user_ids], N=top_k, filter_already_liked_items=True\n",
    "    )\n",
    "\n",
    "    # Substitutes for cold users with the most popular items\n",
    "    rec_items = np.array(\n",
    "        [\n",
    "            popular_items if np.all(scores == 0) else items\n",
    "            for items, scores in zip(rec[0], rec[1])\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return rec_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a673a3-fae0-45e3-b337-dbf2367be75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csr = sparse.csr_matrix(train_mat)\n",
    "valid_csr = sparse.csr_matrix(valid_mat)\n",
    "test_csr = sparse.csr_matrix(test_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "7d477dfe-1aa4-4e47-ad42-e9638f3c2ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "factors = 128\n",
    "regularization = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "9168ed93-2758-4a2c-92d3-c43141f99d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AlternatingLeastSquares(\n",
    "    factors=factors,\n",
    "    regularization=regularization,\n",
    "    iterations=200,\n",
    "    random_state=22,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "5300c9f2-81f8-4989-bdea-09e3c4df8d7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c050baa39f3e4bf88fae3c2a98b3679a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.fit(train_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "e0f3d987-ee5b-48ac-bcf0-59e3706f5157",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predict(\n",
    "    user_ids=test_users,\n",
    "    train_mat=train_csr,\n",
    "    model=model,\n",
    "    popular_items=baseline_topk,\n",
    "    top_k=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "abe14b54-6443-4502-b3be-e8819eceb797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d874e97ee864ebf820dba86597dcf20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9085 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@10 for baseline: 0.053626\n"
     ]
    }
   ],
   "source": [
    "map_at_10 = map_at_k(actual=test_mat[test_users], pred=pred, top_k=10)\n",
    "\n",
    "print(f\"MAP@10 for baseline: {map_at_10:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f91f290-d652-4908-8c2b-d845e5ce07b7",
   "metadata": {},
   "source": [
    "## Write scripts\n",
    "\n",
    "### Prepare the applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "d75acf45-7e33-4c1b-b020-529821ff1767",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_APP_DIR = \"training_app\"\n",
    "os.makedirs(TRAINING_APP_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b499695-6073-48da-a822-5480ea06a9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {TRAINING_APP_DIR}/train.py\n",
    "\n",
    "import fire\n",
    "import hypertune\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Load matrices and files\n",
    "most_common_beers = pd.read_parquet(\"./data/most_common_beers.parquet\")\n",
    "train_mat = np.load(\"../data/matrices/train_mat.npy\")\n",
    "valid_mat = np.load(\"../data/matrices/valid_mat.npy\")\n",
    "\n",
    "with open(\"./data/user_mapper.dict\", \"rb\") as f:\n",
    "    user_mapper = pickle.load(f)\n",
    "with open(\"./data/item_mapper.dict\", \"rb\") as f:\n",
    "    item_mapper = pickle.load(f)\n",
    "\n",
    "# Preprocess\n",
    "baseline_topk = most_common_beers[:10][\"beer_name\"].tolist()\n",
    "valid_users = np.where(valid_mat.sum(axis=1) > 0)\n",
    "\n",
    "train_csr = csr_matrix(train_mat)\n",
    "valid_csr = csr_matrix(valid_mat)\n",
    "\n",
    "def _topk(arr: np.ndarray, k: int) -> np.ndarray:\n",
    "    r\"\"\"Returns indices of k largest element of the given input matrix along\n",
    "    the horizontal axis.\n",
    "    Parameters\n",
    "    ----------\n",
    "    input : np.ndarray\n",
    "        _description_\n",
    "    k : int\n",
    "        _description_\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        _description_\n",
    "    \"\"\"\n",
    "    return np.argsort(arr)[:, -k:][:, ::-1]\n",
    "\n",
    "def map_at_k(actual: np.ndarray, pred: np.ndarray, top_k: int, is_score=False) -> float:\n",
    "    r\"\"\"Mean average precision at k.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : np.ndarray\n",
    "        A matrix with actual values.\n",
    "    pred : np.ndarray\n",
    "        A matrix with predictions.\n",
    "    top_k : int\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Mean average precision at k\n",
    "    \"\"\"\n",
    "    if is_score:\n",
    "        if not _assert_same_dimension(actual, pred):\n",
    "            raise AssertionError(\"Two input matrices should have same dimension.\")\n",
    "    else:\n",
    "        if len(actual) != len(pred):\n",
    "            raise AssertionError(\"Two input matrices should have same length.\")\n",
    "\n",
    "    map_ = 0\n",
    "\n",
    "    num_users = len(pred)\n",
    "    if is_score:\n",
    "        top_k_items = _topk(arr=pred, k=top_k)\n",
    "    else:\n",
    "        top_k_items = pred[:, :top_k]\n",
    "    \n",
    "    for i in range(num_users):\n",
    "        actual_item = set(actual[i].nonzero()[0])\n",
    "        pred_item = top_k_items[i]\n",
    "\n",
    "        map_ += _ap_at_k(actual=actual_item, pred=pred_item, top_k=top_k)\n",
    "        \n",
    "    return map_ / num_users\n",
    "\n",
    "\n",
    "def _ap_at_k(actual: np.array, pred: np.array, top_k: int) -> float:\n",
    "    r\"\"\"Avearge precision at k\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : np.array\n",
    "        A list of item are to be predicted\n",
    "    pred : np.array\n",
    "        A list of predicted items\n",
    "    top_k : int\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Average precision at k\n",
    "    \"\"\"\n",
    "\n",
    "    if len(pred) > top_k:\n",
    "        pred = pred[:top_k]\n",
    "\n",
    "    p, cnt = 0, 0\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    for idx, item in enumerate(pred):\n",
    "        if item in actual:\n",
    "            cnt += 1\n",
    "            p += cnt / (idx + 1)\n",
    "\n",
    "    return 0.0 if cnt == 0 else p / min(cnt, len(actual))\n",
    "\n",
    "def _assert_same_dimension(actual: np.ndarray, pred: np.ndarray) -> bool:\n",
    "    r\"\"\"Check the actual matrix and the prediction have same dimension.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : np.ndarray\n",
    "        Actual values\n",
    "    pred : np.ndarray\n",
    "        Predicted values\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "    \"\"\"\n",
    "    return actual.shape == pred.shape\n",
    "\n",
    "def train(job_dir: str, factors: int, regularization: float, iterations:int, is_tune: bool) -> None:\n",
    "    model = AlternatingLeastSquares(\n",
    "        factors=factors,\n",
    "        regularization=regularization,\n",
    "        iterations=iterations,\n",
    "        random_state=0,\n",
    "    )\n",
    "    model.fit(train_csr)\n",
    "    \n",
    "    if is_tune:\n",
    "        pred = predict(\n",
    "            user_ids=valid_users,\n",
    "            train_mat=train_csr,\n",
    "            model=model,\n",
    "            popular_items=baseline_topk,\n",
    "            top_k=10,\n",
    "        )\n",
    "    \n",
    "\n",
    "def predict(\n",
    "    user_ids: np.ndarray,\n",
    "    train_mat: csr_matrix,\n",
    "    model: AlternatingLeastSquares,\n",
    "    popular_items: list,\n",
    "    top_k: int,\n",
    ") -> np.ndarray:\n",
    "    # Make recommendations based on the model\n",
    "    rec = model.recommend(\n",
    "        user_ids, train_mat[user_ids], N=top_k, filter_already_liked_items=True\n",
    "    )\n",
    "\n",
    "    # Substitutes for cold users with the most popular items\n",
    "    rec_items = np.array(\n",
    "        [\n",
    "            popular_items if np.all(scores == 0) else items\n",
    "            for items, scores in zip(rec[0], rec[1])\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return rec_items\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m93"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
